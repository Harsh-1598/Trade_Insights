{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde481fb",
   "metadata": {},
   "source": [
    "In this code we will fetch the missing datas about the stock like importing the Sectors and Industry of the stock they are trading, buy and sell time and date. Preprocess the data, perform Data Cleaning and at last will do Exploratory Data Analysis to find the hidden patterns and trends in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded14f46",
   "metadata": {},
   "source": [
    "Now we will import the necessary libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b299104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import yfinance as yf\n",
    "from datetime import datetime  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c70596",
   "metadata": {},
   "source": [
    "Now we will load the Dataset to Preprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e0cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "pnl = pd.read_excel(r'Stocks_PnL_3788142010_01-10-2021_11-10-2025_report.xlsx')\n",
    "order_history = pd.read_excel(r'Stocks_Order_History_3788142010_01-10-2021_11-10-2025.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b80720",
   "metadata": {},
   "source": [
    "Now let's find some information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl.info()\n",
    "pnl.shape\n",
    "pnl.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9967eff",
   "metadata": {},
   "source": [
    "similarly for the Order's history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cebbd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_history.info()\n",
    "order_history.shape\n",
    "order_history.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d31ca2",
   "metadata": {},
   "source": [
    "Now Let's see how the data looks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ab383",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa968eb0",
   "metadata": {},
   "source": [
    "Similarly for the Order history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce09835",
   "metadata": {},
   "source": [
    "Now lets fetch the execution date and time for both the buy and sell orders from the order history to the pnl to do the further preprocesses and find the time-based analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Code to Split 'Execution Date and time' into Separate Columns\n",
    "\n",
    "# 1. Convert 'Execution date and time' to datetime\n",
    "order_history['Execution DateTime'] = pd.to_datetime(order_history['Execution date and time'])\n",
    "\n",
    "# 2. Extract Date and Time into separate columns\n",
    "order_history['Execution Date'] = order_history['Execution DateTime'].dt.date  # Only date\n",
    "order_history['Execution Time'] = order_history['Execution DateTime'].dt.time  # Only time\n",
    "\n",
    "# 3. Drop the original column (optional)\n",
    "order_history.drop('Execution date and time', axis=1, inplace=True)\n",
    "\n",
    "# 4. Save updated file\n",
    "order_history.to_excel('Stocks_Order_History_3788142010_01-10-2021_11-10-2025.xlsx', index=False)\n",
    "\n",
    "print(\"Execution Date & Time alag ho gaya! Check 'Stocks_Order_History_3788142010_01-10-2021_11-10-2025.xlsx'\")\n",
    "\n",
    "# Convert to datetime\n",
    "pnl['Buy date'] = pd.to_datetime(pnl['Buy date']).dt.date\n",
    "pnl['Sell date'] = pd.to_datetime(pnl['Sell date']).dt.date\n",
    "\n",
    "# Function to validate market hours (9:15 AM to 3:30 PM)\n",
    "def is_market_time(dt):\n",
    "    if not pd.isna(dt):\n",
    "        time = dt.time()\n",
    "        return (time >= pd.Timestamp('09:15:00').time()) & (time <= pd.Timestamp('15:30:00').time())\n",
    "    return False\n",
    "\n",
    "# Match Buy/Sell Times from Order History\n",
    "def get_times_from_order_history(pnl_row, order_df):\n",
    "    stock_name = pnl_row['Stock name']\n",
    "    isin = pnl_row['ISIN']\n",
    "    quantity = pnl_row['Quantity']\n",
    "    buy_date = pnl_row['Buy date']\n",
    "    sell_date = pnl_row['Sell date']\n",
    "    \n",
    "    # Filter relevant orders\n",
    "    stock_orders = order_df[\n",
    "        (order_df['Stock name'] == stock_name) & \n",
    "        (order_df['ISIN'] == isin)\n",
    "    ].copy()\n",
    "    \n",
    "    # Case 1: Intraday (Buy & Sell same day)\n",
    "    if buy_date == sell_date:\n",
    "        buy_order = stock_orders[\n",
    "            (stock_orders['Execution DateTime'].dt.date == buy_date) &\n",
    "            (stock_orders['Type'] == 'BUY') &\n",
    "            (stock_orders['Execution DateTime'].apply(is_market_time))\n",
    "        ].sort_values('Execution DateTime').head(1)\n",
    "        \n",
    "        sell_order = stock_orders[\n",
    "            (stock_orders['Execution DateTime'].dt.date == sell_date) &\n",
    "            (stock_orders['Type'] == 'SELL') &\n",
    "            (stock_orders['Execution DateTime'].apply(is_market_time))\n",
    "        ].sort_values('Execution DateTime').tail(1)\n",
    "    \n",
    "    # Case 2: Delivery (Different dates)\n",
    "    else:\n",
    "        buy_order = stock_orders[\n",
    "            (stock_orders['Execution DateTime'].dt.date == buy_date) &\n",
    "            (stock_orders['Type'] == 'BUY') &\n",
    "            (stock_orders['Execution DateTime'].apply(is_market_time))\n",
    "        ].sort_values('Execution DateTime').head(1)\n",
    "        \n",
    "        sell_order = stock_orders[\n",
    "            (stock_orders['Execution DateTime'].dt.date == sell_date) &\n",
    "            (stock_orders['Type'] == 'SELL') &\n",
    "            (stock_orders['Execution DateTime'].apply(is_market_time))\n",
    "        ].sort_values('Execution DateTime').tail(1)\n",
    "    \n",
    "    # Extract times\n",
    "    buy_time = buy_order['Execution DateTime'].iloc[0].time() if not buy_order.empty else pd.Timestamp('09:15:00').time()\n",
    "    sell_time = sell_order['Execution DateTime'].iloc[0].time() if not sell_order.empty else pd.Timestamp('15:30:00').time()\n",
    "    \n",
    "    return buy_time, sell_time\n",
    "\n",
    "# Apply to PnL\n",
    "pnl[['Buy Time', 'Sell Time']] = pnl.apply(\n",
    "    lambda row: pd.Series(get_times_from_order_history(row, order_history)), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "order_history.drop('Execution DateTime', axis=1, inplace=True)\n",
    "\n",
    "# Save\n",
    "pnl.to_excel('Stocks_PnL_3788142010_01-10-2021_11-10-2025_report.xlsx', index=False)\n",
    "print(\"Done! File saved with accurate buy/sell times (9:15 AM - 3:30 PM).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af64bfc",
   "metadata": {},
   "source": [
    "Similarly, now let's fetch the sectors and industry for each of the trades to find the sector-based and industry-based trends and patterns in the user trade history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create symbol mapping from order history (Symbol to Stock name)\n",
    "symbol_to_name = dict(zip(order_history['Symbol'], order_history['Stock name']))\n",
    "name_to_symbol = {v: k for k, v in symbol_to_name.items()}\n",
    "\n",
    "# Get unique symbols from order history\n",
    "unique_symbols = order_history['Symbol'].unique()\n",
    "\n",
    "# Fetch sector data\n",
    "sector_data = {}\n",
    "for symbol in unique_symbols:\n",
    "    try:\n",
    "        ticker = yf.Ticker(f\"{symbol}.NS\")\n",
    "        info = ticker.info\n",
    "        sector_data[symbol] = (\n",
    "            info.get('sector', 'Unknown'),\n",
    "            info.get('industry', 'Unknown')\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {symbol}: {str(e)}\")\n",
    "        sector_data[symbol] = ('Unknown', 'Unknown')\n",
    "\n",
    "# Add to order history\n",
    "order_history['Sector'] = order_history['Symbol'].map(lambda x: sector_data.get(x, ('Unknown', 'Unknown'))[0])\n",
    "order_history['Industry'] = order_history['Symbol'].map(lambda x: sector_data.get(x, ('Unknown', 'Unknown'))[1])\n",
    "\n",
    "# Add to PnL - first extract symbol from stock name\n",
    "pnl['Symbol'] = pnl['Stock name'].map(name_to_symbol)\n",
    "pnl['Sector'] = pnl['Symbol'].map(lambda x: sector_data.get(x, ('Unknown', 'Unknown'))[0])\n",
    "pnl['Industry'] = pnl['Symbol'].map(lambda x: sector_data.get(x, ('Unknown', 'Unknown'))[1])\n",
    "\n",
    "# Save files\n",
    "order_history.to_excel('Stocks_Order_History_3788142010_01-10-2021_11-10-2025.xlsx', index=False)\n",
    "pnl.to_excel('Stocks_PnL_3788142010_01-10-2021_11-10-2025_report.xlsx', index=False)\n",
    "\n",
    "print(\"Sector and Industry data added successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28230bea",
   "metadata": {},
   "source": [
    "Since we imported the necessary Timing and Sectorial datas for the trades, now we will be moving towards the Data Cleaning part and afterwards we will apply some EDA techniques to find some hidden patterns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb9954",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f19c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the information of the datasets again after the preprocessing\n",
    "pnl.info()\n",
    "pnl.shape\n",
    "pnl.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9356c58b",
   "metadata": {},
   "source": [
    "Since the realised profit and loss is not calculating the charges, taxes and brokerages paid by the user to the Broker and Exchange so we will be calculating them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Calculate the Charges, Taxes and Brokerages for each of the trades.\n",
    "# Calculating the Brokerage\n",
    "pnl['Brokerage'] = (pnl['Buy value'] + pnl['Sell value']) * 0.0005\n",
    "pnl['Brokerage'] = pnl['Brokerage'].apply(lambda x: min(x, 20)) *(1.18)\n",
    "\n",
    "# Calculating the Exchange Charges, SEBI Charges and Investor Protection Fund\n",
    "pnl['Exchange Charges'] = (pnl['Buy value'] + pnl['Sell value']) * 0.0000297 *(1.18)\n",
    "pnl['SEBI Charges'] = (pnl['Buy value'] + pnl['Sell value']) * 0.000001 *(1.18)\n",
    "pnl['Investor Protection Fund'] = (pnl['Buy value'] + pnl['Sell value']) * 0.000001 *(1.18)\n",
    "\n",
    "# Initialize columns\n",
    "pnl['STT'] = 0\n",
    "pnl['Stamp Duty'] = 0\n",
    "\n",
    "# For Intraday\n",
    "pnl.loc[pnl['Remark'] == 'Intraday', 'STT'] = pnl['Sell value'] * 0.00025  *(1.18)\n",
    "pnl.loc[pnl['Remark'] == 'Intraday', 'Stamp Duty'] = pnl['Buy value'] * 0.00003 *(1.18)\n",
    "pnl.loc[pnl['Remark'] == 'Intraday', 'Demat Charges'] = 0 *(1.18)\n",
    "\n",
    "# For Delivery (or others)\n",
    "pnl.loc[pnl['Remark'] != 'Intraday', 'STT'] = (pnl['Sell value'] + pnl['Buy value']) * 0.001 *(1.18)\n",
    "pnl.loc[pnl['Remark'] != 'Intraday', 'Stamp Duty'] = pnl['Buy value'] * 0.00015 *(1.18)\n",
    "pnl.loc[pnl['Remark'] != 'Intraday', 'Demat Charges'] = 13.5 *(1.18)\n",
    "\n",
    "# For IPO\n",
    "pnl.loc[pnl['Remark'] == 'New shares credit from IPO', 'STT'] = (pnl['Sell value']) * 0.001 *(1.18)\n",
    "pnl.loc[pnl['Remark'] == 'New shares credit from IPO', 'Stamp Duty'] = 0 *(1.18)\n",
    "pnl.loc[pnl['Remark'] == 'New shares credit from IPO', 'Exchange Charges'] = (pnl['Sell value']) * 0.0000297 *(1.18)\n",
    "pnl.loc[pnl['Remark'] == 'New shares credit from IPO', 'SEBI Charges'] = (pnl['Sell value']) * 0.000001 *(1.18)\n",
    "pnl.loc[pnl['Remark'] == 'New shares credit from IPO', 'Investor Protection Fund'] = (pnl['Sell value']) * 0.000001 *(1.18)\n",
    "\n",
    "# Calculating the Total Charges including GST\n",
    "pnl['Total Charges'] = (pnl['Brokerage'] + pnl['STT'] + pnl['Exchange Charges'] + pnl['SEBI Charges'] + pnl['Investor Protection Fund'] + pnl['Stamp Duty'] + pnl['Demat Charges'])\n",
    "\n",
    "# Since we have calculated the charges, taxes and brokerages for each of the trades, we can now drop the unnecessary columns.\n",
    "charges_to_drop = ['STT', 'Exchange Charges', 'SEBI Charges', 'Investor Protection Fund', 'Stamp Duty', 'Demat Charges']\n",
    "pnl = pnl.drop(columns=charges_to_drop)\n",
    "\n",
    "# Adding a new column for Total charges in the PnL dataset\n",
    "pnl['Total Charges'] = pnl['Total Charges'].round(4)\n",
    "pnl.to_excel('Stocks_PnL_3788142010_01-10-2021_11-10-2025_report.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24cf52",
   "metadata": {},
   "source": [
    "Now, let's find the Gross and Net pnl and pnl % to better understand the profits and losses. This will give the idea of overall profits user generates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Gross and Net pnl and pnl %\n",
    "pnl['Gross Realised P&L'] = pnl['Sell value'] - pnl['Buy value']\n",
    "pnl['Gross Realised PnL %'] = (pnl['Gross Realised P&L'] / pnl['Buy value']) * 100\n",
    "pnl['Net Realised P&L'] = pnl['Gross Realised P&L'] - pnl['Total Charges']\n",
    "pnl['Net Realised PnL %'] = (pnl['Net Realised P&L'] / pnl['Buy value']) * 100\n",
    "pnl = pnl.drop(columns= 'Realised P&L')\n",
    "pnl.to_excel('Stocks_PnL_3788142010_01-10-2021_11-10-2025_report.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b7be82",
   "metadata": {},
   "source": [
    "Now, let's find the holding period to understand the user's preference and find the most profitable number of days for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime\n",
    "pnl['Buy date'] = pd.to_datetime(pnl['Buy date'], dayfirst=True)\n",
    "pnl['Sell date'] = pd.to_datetime(pnl['Sell date'], dayfirst=True)\n",
    "\n",
    "# 1. Calculate Holding Period (in days)\n",
    "pnl['Holding Period (Days)'] = (pnl['Sell date'] - pnl['Buy date']).dt.days\n",
    "pnl.to_excel('Stocks_PnL_3788142010_01-10-2021_11-10-2025_report.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349f029",
   "metadata": {},
   "source": [
    "Now, let's find out if any missing values are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd7761",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl.isnull().sum()\n",
    "pnl.info()\n",
    "pnl.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c049129",
   "metadata": {},
   "source": [
    "Since Remarks have so many missing values, lets fill them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70902b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl['Remark'].value_counts()\n",
    "pnl['Remark'] = pnl['Remark'].fillna('Regular trade')\n",
    "pnl['Remark'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
